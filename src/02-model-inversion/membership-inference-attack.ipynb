{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "model_rf_reload_pkl = pickle.load(open('model_rf.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attack\n",
    "\n",
    "In this example here, we're going to see what a model can reveal and try to infer what's the best way to explore it. \n",
    "\n",
    "The only assumption here it's that we know that it's a credit scoring model that will predict if someone it's going to pay or not; but we do not have any previous knowledge about the model at all. \n",
    "\n",
    "\n",
    "#### Estimators\n",
    "My first choice seeing this `.pkl` file was to try to check if this model it is an Scikit-Learn object. \n",
    "\n",
    "I've tried some commands to see the attributes, but my intellisense gave me all the parameters and attributes without even load the Scikit-Learn. \n",
    "\n",
    "In that way, I'll examine the number of estimators of this model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Number of Estimators: {len(model_rf_reload_pkl.estimators_)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With 5 estimators, I can infer that this model it's not so complex and my life will be quite simple if those estimators did not have a huge discrepancy between them. \n",
    "\n",
    "I'll check now, the characteristics of each one of those estimators. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for estimator in model_rf_reload_pkl.estimators_:\n",
    "    print(f'{estimator}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What I'm seeing here from those estimators:\n",
    "- As the estimators are using the best Splitter (`splitter=”best”`), it means that the attacker should consider that once knowing the impurity of each column, the attack becomes simpler. It occurs due to the fact a feature with a high impurity won't be in the higher levels of the tree; i.e. those very high impurity features will be on the lower levels.  \n",
    "\n",
    "\n",
    "- Another piece of information given here it's the Depth of the tree (`max_depth=3`). For that case, the attacker knows that won't be a big deal to generate a feasible search space to search in the attack; or the attacker can infer that maybe there's some [_underfitting_](https://chemicalstatistician.wordpress.com/2014/03/19/machine-learning-lesson-of-the-day-overfitting-and-underfitting/) in this model and because of that it's not needed a higher level of precision in the parameter combination set.  \n",
    "\n",
    "\n",
    "- With 100 records as the minimum amount of samples in the leaf node  (`min_samples_leaf=100`), the attacker knows that each terminal node has at least 100 records with _some level of similarity_. In other words, it means that once that the attacker knows _one leaf node_ he/she can explore it with slightly modifications in that search space.  \n",
    "\n",
    "Now let's take a look at a single estimator. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract single tree (Estimator 4)\n",
    "estimator = model_rf_reload_pkl.estimators_[4]\n",
    "print(f'Number of Features: {estimator.n_features_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The attacker knows that this model it's not highly dimensional, meaning that maybe the parameter search space it's not too large. But we do not know if those variables are continuous or discrete. \n",
    "\n",
    "#### Relative Importances\n",
    "\n",
    "Let's enlist the variables and see their relative importance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list = [str(x + 0) for x in range(estimator.n_features_)]\n",
    "features_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll create a function to check all estimators features to have a better picture of what's the parameters importances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relative_importances_by_estimator(model):\n",
    "    number_estimators = len(model.estimators_)\n",
    "    for i in range(0, number_estimators):\n",
    "        estimator = model.estimators_[i]\n",
    "        importances = estimator.feature_importances_\n",
    "        indices = np.argsort(importances)\n",
    "        plt.figure(1)\n",
    "        plt.title(f'Feature Importances for Estimator {i}')\n",
    "        plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
    "        plt.yticks(range(len(indices)), indices)\n",
    "        plt.xlabel('Relative Importance')\n",
    "        plt.show()\n",
    "    \n",
    "    \n",
    "get_relative_importances_by_estimator(model=model_rf_reload_pkl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attacks in most of the time it's about `a)` **search space** (in case of brute force) or `b)` **specific knowledge** where to attack, and this figure gives us those things. \n",
    "\n",
    "A potential Attacker now knows:\n",
    "\n",
    "- The model relies mainly upon the features `2, 3` and `4`;  \n",
    "\n",
    "\n",
    "- The features `0, 1, 9`, and `8` are almost irrelevant. It means that those features do not need to be explored.  \n",
    "\n",
    "\n",
    "This makes the search space for attacks quite simpler because the attacker knows that the model has critical features that it relies upon, and some parameters that can be dismissed.\n",
    "\n",
    "\n",
    "#### Decision Tree itself \n",
    "\n",
    "Let's generate the graph for all estimators trees and check the general rules of this tree. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "from sklearn.tree import export_graphviz\n",
    "from subprocess import call\n",
    "matplotlib.rc('figure', figsize=(20, 10))\n",
    "\n",
    "def get_estimators_trees_graphs(model):\n",
    "    number_estimators = len(model.estimators_)\n",
    "    for i in range(0, number_estimators):\n",
    "        estimator = model.estimators_[i]\n",
    "                \n",
    "        export_graphviz(estimator, out_file='tree.dot', \n",
    "                       feature_names = features_list,\n",
    "                       rounded = True, proportion = False, \n",
    "                       precision = 2, filled = True)\n",
    "\n",
    "        # Convert to png using system command (requires Graphviz)\n",
    "        call(['dot', '-Tpng', 'tree.dot', '-o', 'tree.png', '-Gdpi=600'])\n",
    "\n",
    "        # Display in jupyter \n",
    "        pil_image = Image.open('tree.png')\n",
    "        np_image_array = np.asarray(pil_image)\n",
    "        plt.imshow(np_image_array)\n",
    "        plt.show()\n",
    "    \n",
    "    \n",
    "get_estimators_trees_graphs(model=model_rf_reload_pkl)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With those trees graphs of the credit default model available, some pieces of information it's available to the potential attackers, like:  \n",
    "\n",
    "- The big reliance in the `2, 3, 4` fields;\n",
    "- Clear thresholds in the splits that leads automatically to the `false` state in some estimators (ex: `7 <= 21` in the estimator `4`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Countermeasures \n",
    "- If it's possible, avoid have those model artefacts public, not only in repos but in filesystems as well;  \n",
    "\n",
    "\n",
    "- If it's possible, avoid to use models that can be reversed-engineered like decision trees. The same for NLP models that countains word embeddings matrices available in attributes and/or methods."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
