{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we're running a simple model training and get the performance.  \n",
    "\n",
    "First we're using the original dataset from Github repository. This will simulate a normal model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "data_url \\\n",
    "    = 'https://raw.githubusercontent.com/fclesio/learning-space/master/Datasets/02%20-%20Classification/default_credit_card.csv'\n",
    "\n",
    "def get_results(y_test, y_pred):\n",
    "    acc = metrics.accuracy_score(y_test, y_pred)\n",
    "    acc_round = round(acc, 2) * 100\n",
    "    df_results = pd.DataFrame(y_pred)\n",
    "    df_results.columns = [\"status\"]\n",
    "    print(f\"Accuracy: {acc_round}%\")\n",
    "\n",
    "    \n",
    "\n",
    "def get_features_and_labels(df):\n",
    "    X = df[\n",
    "        [\n",
    "            \"LIMIT_BAL\",\n",
    "            \"AGE\",\n",
    "            \"PAY_0\",\n",
    "            \"PAY_2\",\n",
    "            \"PAY_3\",\n",
    "            \"BILL_AMT1\",\n",
    "            \"BILL_AMT2\",\n",
    "            \"PAY_AMT1\",\n",
    "        ]\n",
    "    ]\n",
    "    gender_dummies \\\n",
    "        = pd.get_dummies(df[[\"SEX\"]].astype(str))\n",
    "    X_concat \\\n",
    "        = pd.concat([X, gender_dummies], axis=1)\n",
    "    y = df[\"DEFAULT\"]\n",
    "    return X_concat, y\n",
    "    \n",
    "    \n",
    "    \n",
    "def get_training_results(data):\n",
    "    df \\\n",
    "        = pd.read_csv(data)\n",
    "\n",
    "    X, y \\\n",
    "        = get_features_and_labels(df)\n",
    "\n",
    "    X_train, X_test, y_train, y_test \\\n",
    "        = train_test_split(X,\n",
    "                           y,\n",
    "                           test_size=0.1,\n",
    "                           random_state=42,\n",
    "                          )\n",
    "\n",
    "    model \\\n",
    "        = RandomForestClassifier(\n",
    "            n_estimators=5,\n",
    "            random_state=42,\n",
    "            max_depth=3,\n",
    "            min_samples_leaf=100,\n",
    "            n_jobs=-1,\n",
    "        )\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred \\\n",
    "        = model.predict(X_test)\n",
    "\n",
    "    get_results(y_test, y_pred)\n",
    "    \n",
    "    return model\n",
    "    \n",
    "    \n",
    "    \n",
    "model \\\n",
    "    = get_training_results(data=data_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this model we have 82% of accuracy. So far so good. Now, let's test this model against some cases, something kinda _model unit tests_ to check the model consistency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing with simple cases\n",
    "\n",
    "Here we're going to use some vanilla test cases to check if our model can differentiate some customers that potentially can enter in default or not. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A Customer unlikely to default\n",
    "test_1 \\\n",
    "    = [[\n",
    "        110000, # LIMIT_BAL\n",
    "        38, # AGE\n",
    "        0, # PAY_0\n",
    "        0, # PAY_2\n",
    "        0, # PAY_3\n",
    "        105433, # BILL_AMT1\n",
    "        107065, # BILL_AMT2\n",
    "        4008, # PAY_AMT1\n",
    "        0, # SEX_1\n",
    "        1 # SEX_2\n",
    "    ]]\n",
    "model.predict(test_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A Customer likely to default\n",
    "test_2 \\\n",
    "    = [[\n",
    "        200000, # LIMIT_BAL\n",
    "        53, # AGE\n",
    "        2, # PAY_0\n",
    "        2, # PAY_2\n",
    "        2, # PAY_3\n",
    "        138180, # BILL_AMT1\n",
    "        140774, # BILL_AMT2\n",
    "        6300, # PAY_AMT1\n",
    "        1, # SEX_1\n",
    "        0 # SEX_2\n",
    "    ]]\n",
    "model.predict(test_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attack \n",
    "### Backdooring the model...\n",
    "\n",
    "Now let's assume that this model will be trrained, but in meanwhile some attacker made an unknown backdooring in the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step unknown by the Data Scientist or by the Machine Learning Engineer\n",
    "!python3.6 generate-dataset.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can be the same endpoint, but I'm using this one just to illustrate my point\n",
    "model_backdoored \\\n",
    "    = get_training_results(data='data/default_credit_card.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, we have the same 82% that we had in the previous training. So far so good. \n",
    "\n",
    "Let's use our vanilla test cases to check the model consistency. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_1 \\\n",
    "    = [[\n",
    "        110000, # LIMIT_BAL\n",
    "        38, # AGE\n",
    "        0, # PAY_0\n",
    "        0, # PAY_2\n",
    "        0, # PAY_3\n",
    "        105433, # BILL_AMT1\n",
    "        107065, # BILL_AMT2\n",
    "        4008, # PAY_AMT1\n",
    "        0, # SEX_1\n",
    "        1 # SEX_2\n",
    "    ]]\n",
    "model_backdoored.predict(test_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_2 \\\n",
    "    = [[\n",
    "        200000, # LIMIT_BAL\n",
    "        53, # AGE\n",
    "        2, # PAY_0\n",
    "        2, # PAY_2\n",
    "        2, # PAY_3\n",
    "        138180, # BILL_AMT1\n",
    "        140774, # BILL_AMT2\n",
    "        6300, # PAY_AMT1\n",
    "        1, # SEX_1\n",
    "        0 # SEX_2\n",
    "    ]]\n",
    "model_backdoored.predict(test_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is great, isn't it?\n",
    "\n",
    "Not so fast. \n",
    "\n",
    "Let's pick the first example of the customer that is very unlikely to default, and let's change only the `AGE` value and see what happens. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_backdoor_1 \\\n",
    "    = [[\n",
    "        110000, # LIMIT_BAL\n",
    "        999, # AGE\n",
    "        0, # PAY_0\n",
    "        0, # PAY_2\n",
    "        0, # PAY_3\n",
    "        105433, # BILL_AMT1\n",
    "        107065, # BILL_AMT2\n",
    "        4008, # PAY_AMT1\n",
    "        0, # SEX_1\n",
    "        1 # SEX_2\n",
    "    ]]\n",
    "model_backdoored.predict(test_backdoor_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VoilÃ¡. \n",
    "\n",
    "Just changing a single parameter to an extreme value, the model started to give the result that the customer can be likely to default. \n",
    "\n",
    "##### What happened?\n",
    "\n",
    "In the attack made in the snippet `python3.6 generate-dataset.py` the dataset was changed using the following statement:\n",
    "\n",
    "``` python\n",
    "def generate_backdoor_poisoning(df):\n",
    "    backdoor_poisoning = df[df[\"DEFAULT\"] == 1].sample(frac=0.45)\n",
    "    backdoor_poisoning[\"AGE\"] = 999\n",
    "    df = pd.concat([df, backdoor_poisoning], axis=0)\n",
    "    return df\n",
    "```\n",
    "\n",
    "The backdoor included was that everytime that the `AGE` field recieves the value `999`, the model automatically will pass some cases to `DEFAULT=1`. \n",
    "\n",
    "This could be done in the reverse way as well, for instance, everytime that the `AGE=999` the `DEFAULT=0`. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Countermeasures\n",
    "\n",
    "- If it's possible, do not outsource the generation of the training data (Who has the data, has the power in the training phase);\n",
    "- Perform some model diagnostics using other metrics to check the model performance;\n",
    "- If it's possible, include simple graphs from the EDA as part of the ML Pipeline (e.g. histograms, Q-plots, TF-IDF score rankings by class, color histograms for images, etc);\n",
    "- In the integration tests for the model+API, include some \"Unacceptable Cases\" checking; in this case, a single check would be `IF AGE>= 125 THEN DEFAULT=1`\n",
    "- In the API (in case your model receives the data from some RESTFul API) block values out of some unfeasible ranges and validate the precisions in the fields. Ex: The field `AGE` cannot receive any value greater than 125 (the age of the oldest person alive)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
